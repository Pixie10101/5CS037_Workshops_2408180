{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b83bfe-de6b-4237-975f-d590ef86ff6e",
   "metadata": {},
   "source": [
    "**Problem 1: Perform a classification task with knn from scratch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ee262-c295-4e9a-83e4-8c5364471d08",
   "metadata": {},
   "source": [
    "In the diabetes dataset, certain columns may contain 0 where it is biologically invalid (e.g., BMI, Glucose, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62730982-b3e1-4148-8580-4f04d2ef2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711f3ba9-62c0-4151-a280-5633ac8c9d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check data types, missing values, and summary statistics\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf441f74-faa2-4832-934f-140919d492c2",
   "metadata": {},
   "source": [
    "# 2. Handle Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7eba3d-9e08-4b47-b484-68f86b944cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and handle appropriately\n",
    "# Example: Replace zeros in specific columns with the mean or median\n",
    "columns_to_impute = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in columns_to_impute:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Verify no missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524d40a-3bb0-4438-953a-117d775c3404",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25476f2-ec5a-4cbf-8c37-342974a66aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "# Manual train-test split\n",
    "train_size = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Verify the split\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f09cb-5021-4778-bc15-0bc7a8f129b4",
   "metadata": {},
   "source": [
    "# Implement KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6b826-85f6-431b-9990-6f42b1369d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance function\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two points.\n",
    "\n",
    "    Args:\n",
    "    point1 (numpy array or pandas Series): The first data point.\n",
    "    point2 (numpy array or pandas Series): The second data point.\n",
    "\n",
    "    Returns:\n",
    "    float: The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    # Calculate the squared differences for each feature and sum them up\n",
    "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "\n",
    "# KNN prediction for a single query\n",
    "def knn_predict_single(query, X_train, y_train, k=3):\n",
    "    \"\"\"\n",
    "    Predict the class for a single query using KNN.\n",
    "\n",
    "    Args:\n",
    "    query (numpy array or pandas Series): The query data point.\n",
    "    X_train (pandas DataFrame): The training data.\n",
    "    y_train (pandas Series): The labels for the training data.\n",
    "    k (int): The number of nearest neighbors to consider. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    int: The predicted class label for the query.\n",
    "    \"\"\"\n",
    "    # Compute the Euclidean distance between the query point and each training point\n",
    "    distances = [euclidean_distance(query, x) for x in X_train.values]\n",
    "    \n",
    "    # Sort the distances and get the indices of the k nearest neighbors\n",
    "    sorted_indices = np.argsort(distances)[:k]\n",
    "    \n",
    "    # Get the corresponding labels of the k nearest neighbors\n",
    "    nearest_labels = y_train.iloc[sorted_indices]\n",
    "    \n",
    "    # Predict the most frequent class label (majority vote)\n",
    "    prediction = np.bincount(nearest_labels).argmax()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# KNN prediction for all test samples\n",
    "def knn_predict(X_test, X_train, y_train, k=3):\n",
    "    \"\"\"\n",
    "    Predict the classes for all test samples using KNN.\n",
    "\n",
    "    Args:\n",
    "    X_test (pandas DataFrame): The test data.\n",
    "    X_train (pandas DataFrame): The training data.\n",
    "    y_train (pandas Series): The labels for the training data.\n",
    "    k (int): The number of nearest neighbors to consider. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The predicted class labels for all test samples.\n",
    "    \"\"\"\n",
    "    # Predict the class for each test sample using knn_predict_single\n",
    "    return np.array([knn_predict_single(query, X_train, y_train, k) for query in X_test.values])\n",
    "\n",
    "# Evaluate performance of KNN\n",
    "try:\n",
    "    predictions = knn_predict(X_test, X_train, y_train, k=3)  # Run the KNN prediction function\n",
    "    accuracy = (predictions == y_test.values).mean() * 100  # Calculate accuracy\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")  # Print accuracy if successful\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the prediction or accuracy calculation: {e}\")  # Print a user-friendly error message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244c93-d4bc-4fa1-93c6-04af881011d9",
   "metadata": {},
   "source": [
    "# Problem-2 : Experimentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83c5f6-3793-4464-aa63-da5b124d7f8e",
   "metadata": {},
   "source": [
    "### Repeat the classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3499296d-d37c-4cf1-acd8-e4bf0698e96d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Apply scaling to the feature matrix X\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m scale_data(\u001b[43mX\u001b[49m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_scaled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData scaling failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Manually scale the data\n",
    "def scale_data(X):\n",
    "    \"\"\"\n",
    "    Scale the feature matrix X using Z-score normalization (standardization).\n",
    "\n",
    "    Args:\n",
    "    X (pandas DataFrame): The feature matrix to be scaled.\n",
    "\n",
    "    Returns:\n",
    "    pandas DataFrame: The scaled feature matrix.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate the mean and standard deviation for each feature\n",
    "        mean = X.mean(axis=0)\n",
    "        std = X.std(axis=0)\n",
    "        \n",
    "        # Apply Z-score normalization (standardization)\n",
    "        X_scaled = (X - mean) / std\n",
    "        return X_scaled\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data scaling: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply scaling to the feature matrix X\n",
    "X_scaled = scale_data(X)\n",
    "if X_scaled is None:\n",
    "    print(\"Data scaling failed.\")\n",
    "else:\n",
    "    # 2. Split the data into training and testing sets (using a 70%-30% split as per the problem)\n",
    "    train_size = int(0.7 * len(X))  # 70% training data\n",
    "\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets based on a 70%-30% ratio.\n",
    "\n",
    "    Args:\n",
    "    X (pandas DataFrame): The feature matrix.\n",
    "    y (pandas Series): The target variable.\n",
    "\n",
    "    Returns:\n",
    "    X_train_scaled (pandas DataFrame): The scaled training feature matrix.\n",
    "    X_test_scaled (pandas DataFrame): The scaled testing feature matrix.\n",
    "    y_train (pandas Series): The training target variable.\n",
    "    y_test (pandas Series): The testing target variable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split the scaled data into training and testing sets\n",
    "        X_train_scaled, X_test_scaled = X_scaled[:train_size], X_scaled[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data splitting: {e}\")\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test = None, None, None, None\n",
    "\n",
    "    if X_train_scaled is None or X_test_scaled is None:\n",
    "        print(\"Data splitting failed.\")\n",
    "    else:\n",
    "        # 3. Train and test KNN on scaled data using the previously defined knn_predict function\n",
    "        try:\n",
    "            scaled_predictions = knn_predict(X_test_scaled, X_train_scaled, y_train, k=3)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during KNN prediction: {e}\")\n",
    "            scaled_predictions = None\n",
    "\n",
    "        if scaled_predictions is not None:\n",
    "            \"\"\"\n",
    "            Calculate the accuracy of the model by comparing predicted labels to actual labels.\n",
    "\n",
    "            Args:\n",
    "            scaled_predictions (numpy array): The predicted labels from the KNN model.\n",
    "            y_test (pandas Series): The actual labels from the test set.\n",
    "\n",
    "            Returns:\n",
    "            float: The accuracy of the model as a percentage.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                scaled_accuracy = (scaled_predictions == y_test.values).mean() * 100\n",
    "                # Print the accuracy on scaled data\n",
    "                print(f\"Accuracy on scaled data: {scaled_accuracy:.2f}%\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during accuracy calculation: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68339dc-34f9-4dfb-b038-ae6a999a97b9",
   "metadata": {},
   "source": [
    "## Problem - 3: Experimentation with k\n",
    "\n",
    "### 1. Vary the number of neighbors - k:\n",
    "- Run the KNN model on both the original and scaled datasets for a range of:\n",
    "  - \\( k = 1, 2, 3, \\dots, 15 \\)\n",
    "- For each \\( k \\), record:\n",
    "  - Accuracy.\n",
    "  - Time taken to make predictions.\n",
    "\n",
    "### 2. Visualize the Results:\n",
    "- Plot the following graphs:\n",
    "  - k vs. Accuracy for original and scaled datasets.\n",
    "  - k vs. Time Taken for original and scaled datasets.\n",
    "\n",
    "### 3. Analyze and Discuss:\n",
    "- Discuss how the choice of \\( k \\) affects the accuracy and computational cost.\n",
    "- Identify the optimal \\( k \\) based on your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35da0c40-56a0-46de-96ca-fe4ce6270dab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m k_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m evaluate_knn_k_values(\u001b[43mX_train\u001b[49m, y_train, X_test, y_test, X_train_scaled, X_test_scaled, y_train, k_values)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute and print accuracy and time for each k\n",
    "def evaluate_knn_k_values(x_train, y_train, x_test, y_test, x_train_scaled, x_test_scaled, y_train_scaled, k_values):\n",
    "    original_accuracies = []\n",
    "    scaled_accuracies = []\n",
    "    original_times = []\n",
    "    scaled_times = []\n",
    "\n",
    "    # Loop through each k value\n",
    "    for k in k_values:\n",
    "        # Original dataset\n",
    "        start_time = time.time()\n",
    "        predictions = knn_predict(x_test, x_train, y_train, k=k)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        accuracy = (predictions == y_test.values).mean() * 100\n",
    "        original_accuracies.append(accuracy)\n",
    "        original_times.append(elapsed_time)\n",
    "        print(f\"Original Dataset - k = {k}: Accuracy = {accuracy:.2f}%, Time Taken = {elapsed_time:.4f}s\")\n",
    "\n",
    "        # Scaled dataset\n",
    "        start_time = time.time()\n",
    "        scaled_predictions = knn_predict(x_test_scaled, x_train_scaled, y_train_scaled, k=k)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        accuracy = (scaled_predictions == y_test.values).mean() * 100\n",
    "        scaled_accuracies.append(accuracy)\n",
    "        scaled_times.append(elapsed_time)\n",
    "        print(f\"Scaled Dataset - k = {k}: Accuracy = {accuracy:.2f}%, Time Taken = {elapsed_time:.4f}s\")\n",
    "\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(k_values, original_accuracies, label='Original Dataset', marker='o')\n",
    "    plt.plot(k_values, scaled_accuracies, label='Scaled Dataset', marker='o')\n",
    "    plt.xlabel('k (Number of Neighbors)')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('k vs. Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Time Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(k_values, original_times, label='Original Dataset', marker='o')\n",
    "    plt.plot(k_values, scaled_times, label='Scaled Dataset', marker='o')\n",
    "    plt.xlabel('k (Number of Neighbors)')\n",
    "    plt.ylabel('Time Taken (seconds)')\n",
    "    plt.title('k vs. Time Taken')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the range of k values\n",
    "k_values = range(1, 16)\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_knn_k_values(X_train, y_train, X_test, y_test, X_train_scaled, X_test_scaled, y_train, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544e7c0-e127-41e8-8a0e-691303ab6f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f70855-f4af-41f8-b330-ec2f95f28b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaaf009-f9b8-4aeb-8b82-5d40e710327c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff9f2c-47bb-49cb-aa63-0f9089353dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a056f5-55bb-427e-98b9-19214e6ed1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc86dcd-1c33-4008-b934-84d0373b44e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
